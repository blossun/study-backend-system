# Artillery를 사용한 부하 테스트(Stress Test)

## 성능 측정을 위한 스크립트
* cpu-test.yml

## 성능 측정
`cpu-test.yaml` 스크립트 실행 후 결과를 `report.json` 파일로 출력한다.

```bash
artillery run --output report.json cpu-test.yaml
```

## 결과 확인
앞서 만들어진 json 결과 파일 `report.json` 를 확인하기 편하게 html 파일로 만든다.

```bash
artillery report ./report.json
```
html 파일을 열어서 그래프로 결과를 확인할 수 있다.

⇒ **http.response_time 에서 응답시간을 확인할 수 있다.**

- 세로 : Response Time(응답시간)
- 가로 : 성능을 측정하는 전체 테스트 시간(초)
- max : 가장 오래걸린 요청 → 응답 시간
- p95 : 전체 HTTP 트랜잭션 중 가장 빠른 것부터 95%까지(거의 대부분의 트래픽이 여기에 포함된다.)
- p50 : 전체 HTTP 트랜잭션 중 가장 빠른 것부터 50%까지(절반의 트래픽이 여기에 포함된다.)
- min : 가장 빠르게 온 요청 → 응답 시간

> 이외에도 p99를 많이 사용한다. 실제 벤치마크를 잴 때에도 p99, p95 그래프를 많이 그린다. p99는 거의 대부분의 트래픽이기 때문에 실제 애플리케이션의 성능에 가깝다.
>

## 부하를 늘리면서 성능 측정 결과의 변화를 확인
- duration과 arrivalRate(vuser수)를 늘려가면서 확인해보자

내가 만든 API의 성능을 측정하려고 한다면, 목표로하는 Latency를 잡아야한다. 만약 200~300ms 정도의 레이턴시를 유지하겠다고 목표를 세웠다면, 현재 차트는 튀는 부분으로 인해 목표 달성이 안된 것이다.

이럴 경우 CPU가 더 많은 서버로 바꾸는 스케일업을 하거나 nginx를 앞에 세워 로드밸런싱을 하여 스케일 아웃을 해줘야 한다.

## Stress Test를 할 때 무엇을 염두 해야할까?

실무에서는 어떤 기준으로 성능을 테스트할까?

> 이 방법은 사람마다 다를 수 있으므로 자신만의 방법을 만들자.
>
1. **항상 예상 TPS보다 여유롭게 성능 목표치를 잡는다.**
    - 만약에 예상 TPS가 1000정도라면 트래픽이 튀는 상황을 대비해 최소 3000~4000 이상으로 여유롭게 인스턴스를 구성해야 한다.
    - 많으면 많을수록 좋겠지만 그만큼 서버 비용이 많이 들게된다.
2. **API에 기대하는 Latency를 만족할 때까지 성능을 테스트해봐야 한다.**
    - Scale-out을 통해 달성할수도 있지만 가장 먼저 확인해 볼 것은 단일 요청에 대한 Latency가 몇인지 확인해본다. (artillery 스크립트 기준으로 가상 유저수를 1로 설정하고 확인)
    - 단일 요청에 대한 Latency가 기대하는 Latency 보다 높다면 이것은 Scale-out으로 해결되지 않는다.
    - Scale-out을 해도 성능이 늘지 않으면 병목을 의심해본다.
    - 대부분 이런 경우 코드가 비효율적으로 작성되었거나 해당 API에서 실행되는 I/O가 병목인 경우가 많다.
    - 그리고 굉장히 많은 경우 네트워크에서 Latency가 발생하는 경우이다.
    - 그렇기 때문에 꼭 여러가지로 확인해보아야 한다.

